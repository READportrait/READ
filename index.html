<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriately as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>READ</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  
  <style>
    /* 图片轮播样式 */
    figure.image {
      margin-bottom: 20px; /* 控制整个figure的下方间距 */
      text-align: center; /* 居中对齐内容 */
    }

    figure.image img {
      max-width: 100%; /* 确保图片不超出容器宽度 */
      height: auto;
      display: block;
      margin: 0 auto 10px auto; /* 居中图片并添加下方间距 */
    }

    figure.image figcaption {
      font-size: 1.1em; /* 增大图注字体 */
      color: #6c757d;
      text-align: center; /* 居中图注 */
      margin-top: 8px; /* 图注与图片之间的间距 */
      width: 80%;
      margin-left: auto;
      margin-right: auto;
    }

    /* 自定义子标题样式 */
    .custom-subtitle {
      font-weight: 600; /* 适当加粗 */
      color: #4a4a4a; /* 可选：自定义颜色 */
      margin-top: 20px; /* 增加h2和h3之间的间距 */
    }

    /* 在子标题前添加圆点 */
    .custom-subtitle::before {
      content: "• "; /* 添加圆点和一个空格 */
      color: #000; /* 圆点颜色，可根据需要调整 */
      font-weight: inherit; /* 继承父元素的字体粗细 */
    }

    .main-title {
      margin-bottom: 0.5rem; /* 调整数值以实现所需的间距 */
    }

    .video-container {
      display: flex;
      justify-content: center; /* 居中所有视频 */
      gap: 1px; /* 将视频之间的间隔从10px增大到20px */
      flex-wrap: wrap; /* 在小屏幕上允许换行 */
      padding: 1px; /* 将内边距从5px增大到10px */
    }

    /* 视频项样式 */
    .video-item {
      flex: 0 1 30%; /* 默认每行显示三个视频 */
      display: flex;
      flex-direction: column; /* 垂直排列视频和图注 */
      align-items: center; /* 居中视频和图注 */
      margin-bottom: 1px; /* 将下方间距从10px增大到20px */
      transition: transform 0.3s; /* 平滑缩放过渡 */
    }

    .video-item-2 {
      flex: 0 1 40%; /* 默认每行显示三个视频 */
      display: flex;
      flex-direction: column; /* 垂直排列视频和图注 */
      align-items: center; /* 居中视频和图注 */
      margin-bottom: 100px; /* 将下方间距从10px增大到20px */
      transition: transform 0.3s; /* 平滑缩放过渡 */
    }

    /* 缩放视频项 */
    .scaled-video {
      transform: scale(0.8); /* 缩放至80% */
      transform-origin: center; /* 从中心缩放 */
    }
    
    .scaled-video-2 {
      transform: scale(0.7); /* 缩放至70% */
      transform-origin: center; /* 从中心缩放 */
    }

    /* 视频样式 */
    .video-item video,
    .video-item-2 video {
      width: 100%; /* 视频宽度保持为容器的100% */
      height: auto; /* 保持视频的纵横比 */
      align-items: center;
      display: block;
      border-radius: 8px; /* 可选：为视频添加圆角 */
    }

    /* 图注样式 */
    .video-figcaption {
      font-size: 1.1em; /* 增大图注字体 */
      color: #6c757d;
      text-align: center; /* 居中图注 */
      margin-top: 8px; /* 图注与视频之间的间距保持为8px */
      width: 100%; /* 确保图注宽度与视频一致 */
      margin-left: auto;
      margin-right: auto;
    }

    .video-prompt {
      font-size: 1.4em;
      font-weight: bold;
      margin-bottom: 0.5em;
      color: #333; /* 主提示文本颜色 */
      text-align: center; /* 居中提示文本 */
      width: 100%; /* 与视频宽度一致 */
      margin: 0 auto 0.5em auto; /* 居中提示并添加下方间距 */
    }

    /* 轮播视频样式 */
    .carousel .item figure {
      text-align: center; /* 居中视频和图注 */
      margin: 0; /* 移除默认的margin */
    }

    .carousel .item video {
      width: 100%; /* 视频宽度保持为容器的100% */
      height: auto; /* 保持视频的纵横比 */
      align-items: center;
      display: block;
      border-radius: 8px; /* 可选：为视频添加圆角 */
    }

    .carousel .video-figcaption {
      font-size: 1.1em; /* 增大图注字体 */
      color: #6c757d;
      text-align: center;
      margin-top: 8px;
      width: 100%;
      margin-left: auto;
      margin-right: auto;
    }

    table {
      border-collapse: collapse;
      width: 100%;
      font-family: Arial, sans-serif;
      text-align: center; /* 确保表格文字水平居中 */
    }
    th, td {
      border: 1px solid #ccc;
      padding: 8px;
      /* 移除 Flexbox 属性 */
      /* display: flex; */
      /* justify-content: center; */
      /* align-items: center; */
      text-align: center; /* 水平居中 */
      vertical-align: middle; /* 垂直居中 */
      font-size: 1em; /* 确保表格文字清晰 */
    }
    th {
      background-color: #f4f4f4;
    }
    tr:nth-child(even) {
      background-color: #f9f9f9;
    }
    .highlight {
      background-color: #e7f6e7; /* Light green for emphasis */
      font-weight: bold;
    }
    .prompt-text {
      font-style: italic; /* 斜体 */
      font-weight: bold;  /* 加粗 */
      color: #6495ED;     /* 设置文字颜色，可以换成你想要的颜色 */
    }


    @media (max-width: 1024px) {
      .video-item,
      .video-item-2 {
        flex: 0 1 45%; /* 中等屏幕上每行显示两个视频 */
      }
      
      .video-item video,
      .video-item-2 video,
      .video-item figcaption,
      .video-item-2 figcaption,
      .video-prompt {
        width: 100%; /* 在中等屏幕上适当调整宽度 */
      }
    }

    @media (max-width: 600px) {
      .video-item,
      .video-item-2 {
        flex: 0 1 100%; /* 小屏幕上每行显示一个视频 */
      }

      .video-item video,
      .video-item-2 video,
      .video-item figcaption,
      .video-item-2 figcaption,
      .video-prompt {
        width: 100%; /* 在小屏幕上视频占满容器宽度 */
      }

      .video-container {
        gap: 10px; /* 将小屏幕上的间隔从5px增大到10px */
        padding: 10px; /* 保持内边距为10px */
      }
    }

    /* 专门为 Image-source/Text-source Emotion Control 部分增加的样式 */
    .emotion-control-container {
      gap: 30px; /* 增加视频之间的间距 */
    }
  </style>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">READ: Real-time and Efficient Asynchronous Diffusion for Audio-driven Talking Head Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Haotian Wang<sup>1</sup>,</span>
              <span class="author-block">Yuzhe Weng<sup>1</sup>,</span>
              <span class="author-block">Jun Du<sup>1</sup>,</span>
              <span class="author-block">Haoran Xu<sup>2</sup>,</span>
              <span class="author-block">Xiaoyan Wu<sup>2</sup>,</span>
              <span class="author-block">Shan He<sup>2</sup>,</span>
              <span class="author-block">Bing Yin<sup>2</sup>,</span>
              <span class="author-block">Cong Liu<sup>2</sup>,</span>
              <span class="author-block">Jianqing Gao<sup>2</sup>,</span>
              <span class="author-block">Qingfeng Liu<sup>1</sup><sup>2</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1&nbsp</sup>NERCSLIP, University of Science of Technology of China<br><sup>2&nbsp</sup>iFLYTEK</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/YOUR_REPO_HERE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/YOUR_REPO_HERE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/YOUR_REPO_HERE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/YOUR_REPO_HERE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The introduction of diffusion models has brought significant advances to the field of audio-driven talking head generation. However, the extremely slow inference speed severely limits the practical implementation of diffusion-based talking head generation models. In this study, we propose READ, the first real-time diffusion-transformer-based talking head generation framework. Our approach first learns a spatiotemporal highly compressed video latent space via a temporal VAE, significantly reducing the token count to accelerate generation. To achieve better audio-visual alignment within this compressed latent space, a pre-trained Speech Autoencoder (SpeechAE) is proposed to generate temporally compressed speech latent codes corresponding to the video latent space. These latent representations are then modeled by a carefully designed Audio-to-Video Diffusion Transformer (A2V-DiT) backbone for efficient talking head synthesis. Furthermore, to ensure temporal consistency and accelerated inference in extended generation, we propose a novel asynchronous noise scheduler (ANS) for both the training and inference process of our framework. The ANS leverages asynchronous add-noise and asynchronous motion-guided generation in the latent space, ensuring consistency in generated video clips. Experimental results demonstrate that READ outperforms state-of-the-art methods by generating competitive talking head videos with significantly reduced runtime, achieving an optimal balance between quality and speed while maintaining robust metric stability in long-time generation.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper method -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
            <figure class="image">
              <img src="static/images/overall.png" alt="Method Image">
              <figcaption class="video-figcaption">
                Figure2.The framework of READ
              </figcaption>
            </figure>
            <p>
              In this research, we introduce READ, the first real-time diffusion-transformer-based talking head generation framework. Our framework incorporates a pre-trained temporal VAE with a high spatiotemporal compression ratio of 32×32×8 pixels per token. To achieve better audio-visual alignment in the compressed latent space, we pre-train a Speech Autoencoder (SpeechAE) by self-supervising to generate temporally compressed speech latent codes that preserve essential acoustic information corresponding to the compressed video latent space. Then, an Audio-to-Video Diffusion Transformer (A2V-DiT) is designed to generate video latents under speech latent conditions efficiently. The whole training and inference process of our framework is under the proposed Asynchronous Noise Scheduler (ANS), which implements an asynchronous add-noise forward process and an asynchronous motion-guided reverse process to effectively generate long-time videos.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper method -->
    
  <!-- 视频展示部分1 -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <!-- 居中的主标题 -->
        <h2 class="title is-3 has-text-centered main-title">Real-time Audio-Driven Talking Head Generation</h2>
        <!-- 子标题，字体更小，居中对齐，并加粗 -->
        <h3 class="subtitle is-4 has-text-centered"> </h3>
        <h3 class="subtitle is-4 custom-subtitle">Expressive Talking Head Generation</h3>
        <div class="video-container">
          <div class="video-item scaled-video">
            <!-- 仅在下方显示图注 -->
            <figure>
              <video poster="" id="video1a_unique" preload="auto" controls>
                <source src="static/videos/caiqian_shouting.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Vocal Source: TED Speech, Female, Shouting
              </figcaption>
            </figure>
          </div>
          <div class="video-item scaled-video">
            <figure>
              <video poster="" id="video2a_unique" preload="auto" controls>
                <source src="static/videos/tuling.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Vocal Source: TED Speech, Male, Speaking
              </figcaption>
            </figure>
          </div>
          <div class="video-item scaled-video">
            <figure>
              <video poster="" id="video3a_unique" preload="auto" controls>
                <source src="static/videos/dianying.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Vocal Source: TED Speech, Female, Talking
              </figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- 结束 视频展示部分1 -->

  <!-- 视频展示部分2 -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <!-- 子标题，字体更小，居中对齐，并加粗 -->
        <h3 class="subtitle is-4 custom-subtitle">Multiple Styles Generation</h3>
        <div class="video-container">
          <div class="video-item scaled-video">
            <figure>
              <video poster="" id="video4a_unique" preload="auto" controls>
                <source src="static/videos/caiqian_shouting.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Shouting: TED Speech
              </figcaption>
            </figure>
          </div>
          <div class="video-item scaled-video">
            <figure>
              <video poster="" id="video5a_unique" preload="auto" controls>
                <source src="static/videos/caiqian_speaking.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Speaking: TED Speech
              </figcaption>
            </figure>
          </div>
          <div class="video-item scaled-video">
            <figure>
              <video poster="" id="video6a_unique" preload="auto" controls>
                <source src="static/videos/caiqian_talking.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Talking: Talk on Higher Education
              </figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- 结束 视频展示部分2 -->
  
  <!-- 轮播视频*4 -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h3 class="subtitle is-4 custom-subtitle">Cross Actors Generation</h3>
        <div id="results-carousel1" class="carousel results-carousel">
          <div class="item item-video1">
            <figure>
              <video poster="" id="video7a_unique" preload="auto" controls>
                <source src="static/videos/male_obama.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Speech: Speech on graduation ceremony, Barack Hussein Obama
              </figcaption>
            </figure>
          </div>
          <div class="item item-video2">
            <figure>
              <video poster="" id="video8a_unique" preload="auto" controls>
                <source src="static/videos/male_xingfu.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Talk: The Pursuit of Happyness, Chris Gardner (Willard Carroll Smith Jr.)
              </figcaption>
            </figure>
          </div>
          <div class="item item-video3">
            <figure>
              <video poster="" id="video9a_unique" preload="auto" controls>
                <source src="static/videos/male_ted.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Speech: TED Speech on AI Technology
              </figcaption>
            </figure>
          </div>
          <div class="item item-video4">
            <figure>
              <video poster="" id="video10a_unique" preload="auto" controls>
                <source src="static/videos/female_obama.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Talk: Talk on Higher Education
              </figcaption>
            </figure>
          </div>
          <div class="item item-video5">
            <figure>
              <video poster="" id="video10ai_unique" preload="auto" controls>
                <source src="static/videos/female_obama1.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Talk: Talk on Higher Education
              </figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End video carousel -->

  <!-- Long-term Generation 部分 -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h3 class="subtitle is-4 custom-subtitle">Long-term Generation Performance</h3>
        <div class="video-container emotion-control-container">
          <div class="video-item-2 scaled-video-2">
            <!-- 仅在上方显示图注 -->
            <div class="video-prompt">
              Long-time Generation Results
            </div>
            <figure>
              <video poster="" id="video13ai_unique" preload="auto" controls>
                <source src="static/videos/man_long1.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </figure>
          </div>
          <div class="video-item-2 scaled-video-2">
            <div class="video-prompt">
              Long-time Generation Results
            </div>
            <figure>
              <video poster="" id="video14ai_unique" preload="auto" controls>
                <source src="static/videos/man_long2.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </figure>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- 结束 Long-term Generation 部分 -->
  
  <!-- 不同语言 -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h3 class="subtitle is-4 custom-subtitle">Different Languages Performance (e.g. Chinese, French, and Portuguese)</h3>
        <div class="video-container">
          <div class="video-item scaled-video">
            <!-- 仅在下方显示图注 -->
            <figure>
              <video poster="" id="video13a_unique" preload="auto" controls>
                <source src="static/videos/female_chinese.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <!-- <figcaption class="video-figcaption">
                Vocal Source: Chinese, Talk
              </figcaption> -->
            </figure>
          </div>
          <div class="video-item scaled-video">
            <figure>
              <video poster="" id="video14a_unique" preload="auto" controls>
                <source src="static/videos/female_france.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <!-- <figcaption class="video-figcaption">
                Vocal Source: French, Speech
              </figcaption> -->
            </figure>
          </div>
          <div class="video-item scaled-video">
            <figure>
              <video poster="" id="video15a_unique" preload="auto" controls>
                <source src="static/videos/female_portuguese.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <!-- <figcaption class="video-figcaption">
                Vocal Source: Portuguese, Speech
              </figcaption> -->
            </figure>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- 结束 不同语言 -->
  
 <!-- Comparison with SOTA Methods-->
 <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered main-title">Comparison with SOTA Methods</h2>
        <h3 class="subtitle is-4"> &nbsp</h3>
        <h3 class="subtitle is-4 custom-subtitle">Overall Comparison</h3>
        <table border="1" cellspacing="0" cellpadding="5" style="border-collapse: collapse; text-align: center; font-family: sans-serif;">
          <thead>
            <tr style="background-color: #f2f2f2;">
              <th style="vertical-align: middle;">Dataset</th>
              <th>Method</th>
              <th>Runtime(s)</th>
              <th>FID (↓)</th>
              <th>FVD (↓)</th>
              <th>Sync-C (↑)</th>
              <th>Sync-D (↓)</th>
              <th>E-FID (↓)</th>
            </tr>
          </thead>
          <tbody>
            <!-- HDTF Dataset -->
            <tr>
              <td rowspan="6" style="vertical-align: middle;">HDTF</td>
              <td>Hallo</td>
              <td>212.002</td>
              <td>15.929</td>
              <td>315.904</td>
              <td>6.995</td>
              <td>7.819</td>
              <td>0.931</td>
            </tr>
            <tr>
              <td>EchoMimic</td>
              <td>124.105</td>
              <td>18.384</td>
              <td>557.809</td>
              <td>5.852</td>
              <td>9.052</td>
              <td><b>0.927</b></td>
            </tr>
            <tr>
              <td>Sonic</td>
              <td>83.584</td>
              <td>16.894</td>
              <td>245.416</td>
              <td>8.525</td>
              <td><b>6.576</b></td>
              <td>0.932</td>
            </tr>
            <tr>
              <td>AniPortrait</td>
              <td>76.778</td>
              <td>17.603</td>
              <td>503.622</td>
              <td>3.555</td>
              <td>10.830</td>
              <td>2.323</td>
            </tr>
            <tr>
              <td>AniTalker</td>
              <td>13.577</td>
              <td>39.155</td>
              <td>514.388</td>
              <td>5.838</td>
              <td>8.736</td>
              <td>1.523</td>
            </tr>
            <tr style="background-color: #e0f2e0;">
              <td>Ours</td>
              <td><b>4.421</b></td>
              <td><b>15.073</b></td>
              <td><b>235.319</b></td>
              <td><b>8.658</b></td>
              <td>6.890</td>
              <td>0.955</td>
            </tr>
            
            <!-- MEAD Dataset -->
            <tr>
              <td rowspan="6" style="vertical-align: middle;">MEAD</td>
              <td>Hallo</td>
              <td>212.002</td>
              <td>52.300</td>
              <td>292.983</td>
              <td>6.014</td>
              <td>8.822</td>
              <td>1.171</td>
            </tr>
            <tr>
              <td>EchoMimic</td>
              <td>124.105</td>
              <td>65.771</td>
              <td>667.999</td>
              <td>5.482</td>
              <td>9.128</td>
              <td>1.448</td>
            </tr>
            <tr>
              <td>Sonic</td>
              <td>83.854</td>
              <td>47.070</td>
              <td><b>218.308</b></td>
              <td>7.501</td>
              <td><b>7.831</b></td>
              <td>1.434</td>
            </tr>
            <tr>
              <td>AniPortrait</td>
              <td>76.778</td>
              <td>54.621</td>
              <td>531.663</td>
              <td>1.189</td>
              <td>13.013</td>
              <td>1.669</td>
            </tr>
            <tr>
              <td>AniTalker</td>
              <td>13.577</td>
              <td>95.131</td>
              <td>621.528</td>
              <td>6.638</td>
              <td>8.184</td>
              <td>1.553</td>
            </tr>
            <tr style="background-color: #e0f2e0;">
              <td>Ours</td>
              <td><b>4.421</b></td>
              <td><b>46.444</b></td>
              <td>224.738</td>
              <td><b>7.672</b></td>
              <td>8.080</td>
              <td><b>1.043</b></td>
            </tr>
          </tbody>
        </table>
      </div>
    </div>
  </section>
  <!-- 结束 Overall comparison -->

  <!-- 轮播视频*2 -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h3 class="subtitle is-4 custom-subtitle">Case Study on Audio-Driven Generation</h3>
        <div id="results-carousel1" class="carousel results-carousel">
          <div class="item item-video1add">
            <figure>
              <video poster="" id="video19a_add" controls>
                <source src="static/videos/male_comparison.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Voice Source: HDTF Dataset
              </figcaption>
            </figure>
          </div>
          <div class="item item-video1">
            <figure>
              <video poster="" id="video19a_unique" preload="auto" controls>
                <source src="static/videos/female_comparison.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <figcaption class="video-figcaption">
                Voice Source: HDTF Dataset
              </figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End video carousel -->
  
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- 更新后的 JavaScript -->
  <script>
    document.addEventListener('DOMContentLoaded', function () {
      // 如果不再使用播放按钮，以下 JavaScript 可以移除或注释掉
      /*
      // 获取所有播放按钮
      const playButtons = document.querySelectorAll('.play-button');

      playButtons.forEach(button => {
          const videoId = button.getAttribute('data-video');
          const video = document.getElementById(videoId);

          // 点击按钮播放或暂停视频
          button.addEventListener('click', function () {
              if (video.paused) {
                  video.play();
                  this.textContent = '暂停播放';
              } else {
                  video.pause();
                  this.textContent = '开始播放';
              }
          });

          // 当视频播放结束时，更新按钮文本
          video.addEventListener('ended', function () {
              button.textContent = '开始播放';
          });
      });
      */

      // 新增功能：当一个视频开始播放时，暂停所有其他视频
      const videos = document.querySelectorAll('video');

      videos.forEach((video) => {
          video.addEventListener('play', () => {
              videos.forEach((vid) => {
                  if (vid !== video && !vid.paused) {
                      vid.pause();
                  }
              });
          });
      });
    });
  </script>
  <!-- Statcounter tracking code -->
    
  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>
</html>
